{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoProcopio/MVP_Predicao_Infarto_Cardiaco/blob/main/Preditor_de_Infarto_Card%C3%ADaco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otEdveLq8Hn0"
      },
      "source": [
        "## Sprint: Qualidade de Software, Segurança e Sistemas Inteligentes\n",
        "## MVP Problema de Classificação: Preditor de Infarto Cardíaco | Engenharia de Software para Sistemas Inteligentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCn8CH4M7wF-"
      },
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import random\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcB0Efd-MS4"
      },
      "source": [
        "## Carga do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29AFuCPtvG_i"
      },
      "source": [
        "# URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/RodrigoProcopio/CAD_Prediction_Database/main/Heart_Attack_Prediction.csv\"\n",
        "\n",
        "# Leitura do arquivo\n",
        "dataset = pd.read_csv(url, sep=',')\n",
        "\n",
        "# Exibe primeiras linhas do dataset\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE4-PIaTAfKX"
      },
      "source": [
        "## Separação em conjunto de treino e conjunto de teste com holdout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEiAm3LEAfPt"
      },
      "source": [
        "# Definindo o tamanho do conjunto de teste\n",
        "test_size = 0.30\n",
        "\n",
        "# Definindo a semente aleatória para reprodutibilidade\n",
        "seed = 7\n",
        "\n",
        "# Convertendo o conjunto de dados para um array numpy\n",
        "array = dataset.values\n",
        "\n",
        "# Selecionando as características (X) e a variável alvo (y) no array\n",
        "X = array[:, 0:16]  # Seleciona as colunas de 0 a 15 como características\n",
        "y = array[:, 16]    # Seleciona a última coluna (índice 16) como variável alvo\n",
        "\n",
        "# Dividindo o conjunto de dados em conjuntos de treino e teste usando a função train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "    test_size=test_size, shuffle=True, random_state=seed, stratify=y)  # Realiza o holdout com estratificação\n",
        "\n",
        "# Configurando parâmetros e partições para a validação cruzada\n",
        "scoring = 'accuracy'  # Métrica de avaliação\n",
        "num_particoes = 2    # Número de partições para validação cruzada\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed)  # Configurando validação cruzada com estratificação"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OGe0DtAfU4"
      },
      "source": [
        "## Modelagem e Inferência"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHzQpbX9QQh"
      },
      "source": [
        "### Criação e avaliação de modelos: linha base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAhfSnnIAfke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62233db6-3ab0-428c-96a0-fac326383b24"
      },
      "source": [
        "# Definindo uma semente global para reprodutibilidade\n",
        "np.random.seed(7)\n",
        "\n",
        "# Lista que armazenará os modelos\n",
        "models = []\n",
        "\n",
        "# Criando e adicionando modelos à lista\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Listas para armazenar os resultados da validação cruzada\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliando o desempenho dos modelos\n",
        "for name, model in models:\n",
        "    # Utilizando a validação cruzada para obter métricas de desempenho\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "\n",
        "    # Armazenando resultados e nomes dos modelos\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "\n",
        "    # Exibindo métricas de desempenho para cada modelo\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Criando um boxplot para comparar os modelos\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "fig.suptitle('Comparação dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN: 0.565536 (0.009292)\n",
            "CART: 0.544017 (0.006358)\n",
            "NB: 0.641832 (0.000163)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olo7SPk2BvvW"
      },
      "source": [
        "### Criação e avaliação de modelos: dados padronizados e normalizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmQbiYQdBRDW"
      },
      "source": [
        "# Definindo uma semente global para reprodutibilidade\n",
        "np.random.seed(7)\n",
        "\n",
        "# Lista que armazenará os modelos\n",
        "models = []\n",
        "\n",
        "# Criando e adicionando modelos à lista\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Listas para armazenar os resultados da validação cruzada\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliando o desempenho dos modelos\n",
        "for name, model in models:\n",
        "    # Utilizando a validação cruzada para obter métricas de desempenho\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "\n",
        "    # Armazenando resultados e nomes dos modelos\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "\n",
        "    # Exibindo métricas de desempenho para cada modelo\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Criando um boxplot para comparar os modelos\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "fig.suptitle('Comparação dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-f2vCU5CMmp"
      },
      "source": [
        "### Otimização dos hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Definindo uma semente global para reprodutibilidade\n",
        "np.random.seed(7)\n",
        "\n",
        "# Definindo os componentes do pipeline para o Naive Bayes (NB)\n",
        "nb = GaussianNB()\n",
        "standard_scaler = StandardScaler()\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# Criando pipelines para o NB com diferentes transformações\n",
        "pipelines_nb = [\n",
        "    ('nb-orig', Pipeline(steps=[('nb', nb)])),\n",
        "    ('nb-padr', Pipeline(steps=[('scaler', standard_scaler), ('nb', nb)])),\n",
        "    ('nb-norm', Pipeline(steps=[('min_max_scaler', min_max_scaler), ('nb', nb)])),\n",
        "]\n",
        "\n",
        "# Não é necessário definir parâmetros para tuning do NB, pois ele não possui hiperparâmetros significativos para otimização\n",
        "\n",
        "# Preparando e executando o GridSearchCV para o NB\n",
        "for name, model in pipelines_nb:\n",
        "    # Configurando GridSearchCV com o modelo do pipeline\n",
        "    grid_nb = GridSearchCV(estimator=model, param_grid={}, scoring=scoring, cv=kfold)\n",
        "\n",
        "    # Ajustando o GridSearchCV com os dados de treino\n",
        "    grid_nb.fit(X_train, y_train)\n",
        "\n",
        "    # Imprimindo a melhor configuração e desempenho\n",
        "    print(f'Tratamento: {name} - Melhor Acurácia: {grid_nb.best_score_:.3f}')"
      ],
      "metadata": {
        "id": "jBSDgpXNt1Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUpaYcwDRDt"
      },
      "source": [
        "## Finalização do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbrFxAbSDVIj"
      },
      "source": [
        "# Avaliação do modelo Naive Bayes (NB) com o conjunto de testes\n",
        "\n",
        "# Preparação do modelo Naive Bayes\n",
        "model_nb_original = GaussianNB()  # Inicializa um modelo Naive Bayes\n",
        "model_nb_original.fit(X_train, y_train)  # Treina o modelo com os dados de treino\n",
        "\n",
        "# Estimativa da acurácia no conjunto de teste\n",
        "predictions_nb_original = model_nb_original.predict(X_test)  # Realiza previsões no conjunto de teste\n",
        "accuracy_nb_original = accuracy_score(y_test, predictions_nb_original)  # Calcula a acurácia\n",
        "print(f'Acurácia do Naive Bayes (sem padronização) no conjunto de teste: {accuracy_nb_original:.3f}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeQHmeg4ziu"
      },
      "source": [
        "# Preparação do modelo com TODO o dataset\n",
        "\n",
        "# Ajuste do scaler com TODOS os dados\n",
        "scaler = StandardScaler().fit(X)  # Inicializa e ajusta o scaler usando o conjunto de dados completo (X)\n",
        "\n",
        "# Aplicação da padronização em TODOS os dados\n",
        "rescaledX = scaler.transform(X)  # Utiliza o scaler ajustado para padronizar o conjunto de dados completo (X)\n",
        "\n",
        "# Treinamento do modelo com os dados padronizados\n",
        "model.fit(rescaledX, y)  # Treina o modelo usando os dados padronizados (rescaledX) e a variável alvo (y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-FQWZj_OtQ"
      },
      "source": [
        "## Simulando a aplicação do modelo em dados não vistos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAIp6d9w5QG8"
      },
      "source": [
        "# Função para mostrar dados aleatórios\n",
        "def mostrar_dados_aleatorios(dados_aleatorios):\n",
        "    for i, dados_aleatorio in enumerate(dados_aleatorios):\n",
        "        print(f\"Simulação {i + 1}: \\n\")\n",
        "        for atributo, valor in dados_aleatorio.items():\n",
        "            print(f\"{atributo}: {valor}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "# Gerando dados aleatórios para simulação\n",
        "num_simulacoes = 2\n",
        "dados_simulados = []\n",
        "\n",
        "# Lista de atributos e intervalos permitidos\n",
        "atributos = {\n",
        "    'Qual sua idade': (18, 99),\n",
        "    'Qual o seu sexo': (0, 1),\n",
        "    'Qual seu nível de colesterol': (120, 400),\n",
        "    'Qual seu batimento cardíaco em repouso': (40, 110),\n",
        "    'Possui diabetes': (0, 1),\n",
        "    'Tem histórico de infarto cardíaco na família': (0, 1),\n",
        "    'É fumante': (0, 1),\n",
        "    'É obeso': (0, 1),\n",
        "    'Faz consumo de ácool com frequência': (0, 1),\n",
        "    'Como é sua alimentação': (0, 2),\n",
        "    'Tem algum problema cardíaco': (0, 1),\n",
        "    'Faz uso de medicamento contínuo': (0, 1),\n",
        "    'Qual seu nível de estresse no dia a dia': (0, 10),\n",
        "    'Qual o valor de triglicerídeos': (30, 800),\n",
        "    'Quantos dias na semana realiza atividade física': (0, 7),\n",
        "    'Quantas horas de sono por dia': (4, 10),\n",
        "}\n",
        "\n",
        "# Loop para gerar dados simulados\n",
        "for _ in range(num_simulacoes):\n",
        "    # Dicionário para armazenar dados simulados para cada atributo\n",
        "    dados_simulacao = {atributo: random.randint(intervalo[0], intervalo[1]) for atributo, intervalo in atributos.items()}\n",
        "\n",
        "    # Adiciona os dados simulados à lista\n",
        "    dados_simulados.append(dados_simulacao)\n",
        "\n",
        "# Convertendo dados simulados para DataFrame\n",
        "entrada_simulada = pd.DataFrame(dados_simulados, columns=atributos)\n",
        "\n",
        "# Convertendo os dados simulados para array\n",
        "array_entrada_simulada = entrada_simulada.values\n",
        "X_entrada_simulada = array_entrada_simulada.astype(float)  # Garante que todos os atributos são numéricos\n",
        "\n",
        "# Padronização nos dados de entrada usando o scaler treinado em X_train\n",
        "rescaledEntradaSimuladaX = scaler.transform(X_entrada_simulada)\n",
        "\n",
        "# Definindo e treinando o modelo Naive Bayes\n",
        "model_nb = GaussianNB()  # Inicializa o modelo Naive Bayes\n",
        "model_nb.fit(X_train, y_train)  # Treina o modelo com os dados de treino\n",
        "\n",
        "# Mostrando dados aleatórios\n",
        "print(\"\\nDados Aleatórios: \\n\")\n",
        "mostrar_dados_aleatorios(dados_simulados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo previsões com o modelo Naive Bayes treinado\n",
        "previsoes_simuladas = model_nb.predict(rescaledEntradaSimuladaX)\n",
        "\n",
        "# Exibindo as previsões\n",
        "for i, previsao in enumerate(previsoes_simuladas):\n",
        "    print(f\"Simulação {i + 1}: Previsão de Classe {previsao}\")"
      ],
      "metadata": {
        "id": "Lg6B7Uz9__to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerando o arquivo .pkl do modelo treinado"
      ],
      "metadata": {
        "id": "YBzcCNqRz0Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo\n",
        "joblib.dump(model_nb, 'modelo_naive_bayes.pkl')\n",
        "\n",
        "# Salvar o scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n"
      ],
      "metadata": {
        "id": "C2wHmSrQyFm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do Processo:\n",
        "\n",
        "## Carregamento e Exploração dos Dados:\n",
        "\n",
        "Os dados foram carregados a partir de uma URL e explorados para entender a estrutura e os tipos de variáveis presentes.\n",
        "\n",
        "## Pré-processamento e Divisão dos Dados:\n",
        "\n",
        "Foram realizadas etapas de pré-processamento, incluindo a divisão do conjunto de dados em conjuntos de treino e teste, estratificados para manter a proporção de classes.\n",
        "\n",
        "## Seleção de Modelos:\n",
        "\n",
        "Foram escolhidos quatro modelos de classificação: KNN (k-Nearest Neighbors), Decision Tree, Naive Bayes e SVM (Support Vector Machine).\n",
        "\n",
        "## Avaliação do Desempenho dos Modelos:\n",
        "\n",
        "Utilizou-se a validação cruzada para avaliar o desempenho dos modelos em termos de acurácia média e variabilidade.\n",
        "\n",
        "## Escolha do Modelo Naive Bayes:\n",
        "\n",
        "O modelo Naive Bayes foi escolhido com base no desempenho médio durante a validação cruzada. Foi observado que o Naive Bayes apresentou uma acurácia média sólida, mesmo que simples, e uma variabilidade muito baixa nos resultados.\n",
        "\n",
        "##Pipeline e Transformações nos Dados:\n",
        "\n",
        "Criou-se pipelines para o Naive Bayes com diferentes transformações nos dados (original, padronizado com StandardScaler, normalizado com MinMaxScaler), embora as transformações não tenham impacto significativo nos resultados finais.\n",
        "\n",
        "##Treinamento do Modelo e Avaliação no Conjunto de Teste:\n",
        "\n",
        "O modelo Naive Bayes foi treinado no conjunto de treino e avaliado no conjunto de teste, obtendo uma acurácia de aproximadamente 64.2%.\n",
        "\n",
        "##Geração de Dados Simulados e Previsões:\n",
        "\n",
        "Foram gerados dados simulados, padronizados com o scaler treinado, e o modelo Naive Bayes foi utilizado para fazer previsões nesses dados simulados.\n",
        "\n",
        "##Salvamento do Modelo e do Scaler:\n",
        "\n",
        "O modelo Naive Bayes e o scaler foram salvos em arquivos para uso futuro.\n",
        "Este mesmo modelo foi utilizado no back-end do MVP Predição Infarto Cardíaco que pode ser encontrado no [GitHub](https://github.com/RodrigoProcopio/MVP_Predicao_Infarto_Cardiaco).\n",
        "\n",
        "##Escolha do Modelo Naive Bayes:\n",
        "O Naive Bayes foi escolhido com base em algumas considerações:\n",
        "\n",
        "##Simplicidade e Eficiência:\n",
        "\n",
        "O Naive Bayes é um modelo simples e eficiente, especialmente adequado para conjuntos de dados menores ou quando há suposições de independência condicional entre as características.\n",
        "\n",
        "##Desempenho Satisfatório:\n",
        "\n",
        "Durante a validação cruzada, o Naive Bayes apresentou uma acurácia média sólida em comparação com outros modelos testados.\n",
        "\n"
      ],
      "metadata": {
        "id": "t-t5TTLqV2xA"
      }
    }
  ]
}